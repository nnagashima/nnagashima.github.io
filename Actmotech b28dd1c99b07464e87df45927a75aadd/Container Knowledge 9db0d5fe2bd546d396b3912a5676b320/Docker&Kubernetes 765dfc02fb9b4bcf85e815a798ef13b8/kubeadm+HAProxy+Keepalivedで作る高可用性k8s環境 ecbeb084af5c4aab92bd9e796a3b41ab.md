# kubeadm+HAProxy+Keepalivedã§ä½œã‚‹é«˜å¯ç”¨æ€§k8sç’°å¢ƒ

![kubernetes-icon-2048x1995-r1q3f8n7.png](kubeadm+HAProxy+Keepalived%E3%81%A6%E3%82%99%E4%BD%9C%E3%82%8B%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7k8s%E7%92%B0%E5%A2%83%20ecbeb084af5c4aab92bd9e796a3b41ab/kubernetes-icon-2048x1995-r1q3f8n7.png)

ç›®æ¬¡

# ã¯ã˜ã‚ã«

---

HAProxy+KeepAlivedã‚’åˆ©ç”¨ã—ãŸé«˜å¯ç”¨æ€§ã®k8sç’°å¢ƒã‚’ä½œã‚Šã¾ã™ã€‚ æ§‹æˆãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ä»¥ä¸‹ã§ã™ã€‚

- k8sã®Masterã¯Rasbbery Pi4ã¨x86 Proxmoxã®VMã§æ§‹ç¯‰ã€Workerã¯x86 Proxmoxã®VMã§å‹•ã‹ã—ã¾ã™ã€‚
- OSã¯Ubuntu24.04ã§æ§‹ç¯‰ã—å‹•ã‹ã—ã¾ã™ã€‚
- NASã¯Synologyã®CSIãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’åˆ©ç”¨ã—ãŸã‹ã£ãŸãŸã‚ã€SynologyNASã‚’è³¼å…¥ã—ã¾ã—ãŸ

# åˆ©ç”¨OS

---

- OSï¼šUbuntu24.04
- k8sï¼š1.30.2

# æ§‹æˆ

---

- 192.168.21.30 KeepAlivedã®VIP
- 192.168.21.31 / 192.168.21. 32 / 192.168.21.33 / 192.168.21.34 / 192.168.21.35ï¼šã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ³ãƒãƒ¼ãƒ‰
- 192.168.21.41 / 192.168.21.42 / 192.168.21.43ï¼šãƒ¯ãƒ¼ã‚«ãƒ¼ãƒãƒ¼ãƒ‰

# äº‹å‰æº–å‚™

---

OSã®PKGã‚’æœ€æ–°åŒ–ã—ã¾ã™ã€‚

```bash
# apt update && apt upgrade -y
```

ãƒ›ã‚¹ãƒˆåã‚’è¨­å®šã—ã¾ã™ã€‚

```bash
# hostnamectl set-hostname hostå
```

# SWAPã®ç„¡åŠ¹åŒ–

---

- å¯¾è±¡ï¼šRasberryPiã®å ´åˆ

RasberryPiã¯cgroupsã®è¨­å®šã‚’ã™ã‚‹ãŸã‚ã«ã€ã‚«ãƒ¼ãƒãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç·¨é›†ã—ã¾ã™ã€‚

Controle Groupã®ç•¥ã§ã€ãƒ—ãƒ­ã‚»ã‚¹ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦ã€åˆ©ç”¨ã‚’åˆ¶é™ã‚’ã‹ã‘ã‚‹ã“ã¨ãŒã§ãã‚‹Linuxã®ã‚«ãƒ¼ãƒãƒ«æ©Ÿèƒ½ã«ãªã‚Šã¾ã™ã€‚

cgroupãŒk8sã§ã„ãã¤ã‹åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€è¨­å®šæœ‰åŠ¹åŒ–å¾Œã«OSå†èµ·å‹•ã—ã¾ã™ã€‚

```bash
# swapoff -a
# sed -i 's/$/ cgroup_enable=cpuset cgroup_memory=1 cgroup_enable=memory/g' /boot/cmdline.txt 
# reboot
```

- å¯¾è±¡ï¼šx86ç³»ã®å ´åˆ

ä»¥ä¸‹ã®é€šã‚Šå®Ÿè¡Œã—ã¾ã™ã€‚

```bash
# swapoff -a
# vi /etc/fstab
swapã®è¨˜è¼‰ãŒã‚ã‚Œã°ç„¡åŠ¹ã«ã™ã‚‹
```

# MicroSDã‹ã‚‰SSDã¸ã®æ›¸ãè¾¼ã¿ã‚’å®Ÿè¡Œã—èµ·å‹•

---

RasberryPiã®å ´åˆã€MicroSDã ã¨èµ·å‹•ãŒä¸å®‰å®šã«ãªã‚‹ã®ã§ã€SSDã«æ›¸ãè¾¼ã¿ã—ã¾ã™ã€‚

ã‚‚ã¡ã‚ã‚“SDã‹ã‚‰ã‚³ãƒ”ãƒ¼ã™ã‚‹ã®ã§ã¯ãªãæœ€åˆã‹ã‚‰USBã®SSDã«OSæ›¸ãè¾¼ã‚“ã§èµ·å‹•ã§ã‚‚å¤§ä¸ˆå¤«ã§ã™ã€‚

ãªãŠã€RassberryPiã¨SSDã®æ¥ç¶šã®ã‚³ãƒ¼ãƒ‰ã¯ç›¸æ€§ãŒã‚ã‚Šã¾ã™ã€‚ç§ã¯ä»¥ä¸‹ã‚³ãƒ¼ãƒ‰ã‚’è³¼å…¥ã—ã¦ãŠã‚Šã¾ã™ã€‚

https://www.amazon.co.jp/gp/product/B00HJZJI84/ref=ppx_yo_dt_b_asin_title_o05_s00?ie=UTF8&psc=1

```bash
# git clone https://github.com/billw2/rpi-clone.git
# cd rpi-clone/
# cp rpi-clone rpi-clone-setup /usr/local/sbin/
# rpi-clone sda -f
Initialize and clone to the destination disk sda? (yes/no):yes
Optional destination ext type file system label (16 chars max): ssd
Hit Enter when ready to unmount the /dev/sda partitions ...
æœ€å¾Œã«Enterã‚’æŠ¼ã—ã¦Unmountã—ã¾ã™ã€‚
æ›¸ãè¾¼ã¿ãŒå®Œäº†ã—ãŸã‚‰raspi-configã‚’åˆ©ç”¨ã—ã¦Bootã‚’MicroSDã‹ã‚‰SSDã«å¤‰æ›´ã—ã¾ã™ã€‚
```

# kubernetesã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

---

ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã«å¿…è¦ãªã‚‚ã®ã‚’ScriptåŒ–ã—ã¾ã—ãŸã€‚

ã‚³ãƒ³ãƒ†ãƒŠãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã«ã¤ã„ã¦ã¯Dockerã€containerdã€CRI-OãŒã‚ã‚Šã¾ã™ã€‚

CRI-Oã«ã¤ã„ã¦ã¯CRI-Oã®ãƒ¡ã‚¸ãƒ£ãƒ¼ã¨ãƒã‚¤ãƒŠãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯Kubernetesã®ãƒ¡ã‚¸ãƒ£ãƒ¼ã¨ãƒã‚¤ãƒŠãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨ä¸€è‡´ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ãŸã‚ã€

åˆ©ç”¨ã™ã‚‹ã«ã¯æ³¨æ„ã—ã¦ãã ã•ã„ã€‚

```bash
#!/bin/bash

###containerd install###
apt-get install -y iptables arptables ebtables
apdate-alternatives --set iptables /usr/sbin/iptables-legacy
update-alternatives --set ip6tables /usr/sbin/ip6tables-legacy
update-alternatives --set arptables /usr/sbin/arptables-legacy
update-alternatives --set ebtables /usr/sbin/ebtables-legacy

cat > /etc/modules-load.d/containerd.conf <<EOF
overlay
br_netfilter
EOF

modprobe overlay
modprobe br_netfilter

cat > /etc/sysctl.d/99-kubernetes-cri.conf <<EOF
net.bridge.bridge-nf-call-iptables  = 1
net.ipv4.ip_forward                 = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF

sysctl --system

apt -y install containerd
mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml

if grep -q "SystemdCgroup = true" "/etc/containerd/config.toml"; then
  echo "Config found, skip rewriting..."
else
  sed -i -e "s/SystemdCgroup \= false/SystemdCgroup \= true/g" /etc/containerd/config.toml
fi

systemctl restart containerd
systemctl enable containerd

###k8s install###
cat <<EOF > /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
sysctl --system

apt update && apt-get install -y apt-transport-https curl gnupg2
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
apt update
apt install -y kubelet=1.30.2-1.1 kubeadm=1.30.2-1.1 kubectl=1.30.2-1.1
apt-mark hold kubelet kubeadm kubectl
```

# HAProxyã®æ§‹ç¯‰

---

- å¯¾è±¡ï¼šã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ³ãƒãƒ¼ãƒ‰å…¨ã¦ã§å®Ÿæ–½

HAProxyã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

```bash
# apt install haproxy
```

HAProxyã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚

```bash
# cat /etc/haproxy/haproxy.cfg
global
    log /dev/log  local0 warning
    chroot      /var/lib/haproxy
    pidfile     /var/run/haproxy.pid
    maxconn     4000
    user        haproxy
    group       haproxy
    daemon

   stats socket /var/lib/haproxy/stats

defaults
  log global
  option  httplog
  option  dontlognull
        timeout connect 5000
        timeout client 50000
        timeout server 50000

frontend kube-apiserver
  bind *:8443
  mode tcp
  option tcplog
  default_backend kube-apiserver

backend kube-apiserver
    mode tcp
    option tcplog
    option tcp-check
    balance roundrobin
    default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100
    server kube-apiserver-1 192.168.21.31:6443 check
    server kube-apiserver-2 192.168.21.32:6443 check
    server kube-apiserver-3 192.168.21.33:6443 check
    server kube-apiserver-4 192.168.21.34:6443 check
    server kube-apiserver-5 192.168.21.35:6443 check
```

 è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ã„ãŸã‚‰HAProxyã®è‡ªå‹•èµ·å‹•æœ‰åŠ¹åŒ–ã¨å†èµ·å‹•ã‚’å®Ÿæ–½ã—ã¾ã™ã€‚

```bash
# systemctl --now enable haproxy; systemctl status haproxy
Synchronizing state of haproxy.service with SysV service script with /usr/lib/systemd/systemd-sysv-install.
Executing: /usr/lib/systemd/systemd-sysv-install enable haproxy
â— haproxy.service - HAProxy Load Balancer
     Loaded: loaded (/usr/lib/systemd/system/haproxy.service; enabled; preset: enabled)
     Active: active (running) since Thu 2024-07-18 19:29:27 JST; 3h 30min ago
       Docs: man:haproxy(1)
             file:/usr/share/doc/haproxy/configuration.txt.gz
   Main PID: 984 (haproxy)
     Status: "Ready."
      Tasks: 5 (limit: 3863)
     Memory: 13.1M (peak: 14.9M)
        CPU: 14.988s
     CGroup: /system.slice/haproxy.service
             â”œâ”€ 984 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.sock
             â””â”€1045 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.sock
```

# Keepalivedã®æ§‹ç¯‰

---

- å¯¾è±¡ï¼šã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ³ãƒãƒ¼ãƒ‰å…¨ã¦ã§å®Ÿæ–½

Keepalivedã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

```bash
# apt install keepalived
```

keepalivedã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚

```bash
# vi /etc/keepalived/keepalived.conf
global_defs {
  notification_email {
  }
  router_id LVS_DEVEL
  vrrp_skip_check_adv_addr
  vrrp_garp_interval 0
  vrrp_gna_interval 0
}

vrrp_script chk_haproxy {
  script "killall -0 haproxy"
  interval 2
  weight 2
}

vrrp_instance haproxy-vip {
  state BACKUP
  priority 100 #PriorityãŒé«˜ã„ã‚‚ã®ã‚’å„ªå…ˆã™ã‚‹
  interface eth0
  virtual_router_id 60
  advert_int 1
  authentication {
    auth_type PASS
    auth_pass 1111
  }
  unicast_src_ip 192.168.21.31 #è¨­å®šã™ã‚‹ãƒãƒ¼ãƒ‰ã®IPã‚¢ãƒ‰ãƒ¬ã‚¹
  unicast_peer {
    192.168.21.32, #ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ³ãƒãƒ¼ãƒ‰ã®IPã‚¢ãƒ‰ãƒ¬ã‚¹
    192.168.21.33,
    192.168.21.34,
    192.168.21.35                         
  }

  virtual_ipaddress {
    192.168.21.30/24 #VIPã‚¢ãƒ‰ãƒ¬ã‚¹
  }

  track_script {
    chk_haproxy
  }
}
```

 è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ã„ãŸã‚‰Keepalivedã®è‡ªå‹•èµ·å‹•æœ‰åŠ¹åŒ–ã¨å†èµ·å‹•ã‚’å®Ÿæ–½ã—ã¾ã™ã€‚

```bash
# systemctl --now enable keepalived
Synchronizing state of keepalived.service with SysV service script with /usr/lib/systemd/systemd-sysv-install.
Executing: /usr/lib/systemd/systemd-sysv-install enable keepalived
root@master03:~# systemctl --now enable keepalived; systemctl status keepalived
Synchronizing state of keepalived.service with SysV service script with /usr/lib/systemd/systemd-sysv-install.
Executing: /usr/lib/systemd/systemd-sysv-install enable keepalived
â— keepalived.service - Keepalive Daemon (LVS and VRRP)
     Loaded: loaded (/usr/lib/systemd/system/keepalived.service; enabled; preset: enabled)
     Active: active (running) since Thu 2024-07-18 19:31:35 JST; 3h 40min ago
       Docs: man:keepalived(8)
             man:keepalived.conf(5)
             man:genhash(1)
             https://keepalived.org
   Main PID: 856 (keepalived)
      Tasks: 2 (limit: 3863)
     Memory: 10.1M (peak: 11.4M)
        CPU: 3min 28.144s
     CGroup: /system.slice/keepalived.service
             â”œâ”€856 /usr/sbin/keepalived --dont-fork
             â””â”€910 /usr/sbin/keepalived --dont-fork
```

# kubernetesã®æ§‹ç¯‰

---

- å¯¾è±¡ï¼šã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ³ãƒãƒ¼ãƒ‰ã®ã©ã“ã‹1å°ã§å®Ÿæ–½

pod-network-cidrã¯è‡ªåˆ†ã®å¥½ããªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ã—ã¦ãã ã•ã„ï¼ˆãƒ›ã‚¹ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ãƒãƒƒãƒ†ã‚£ãƒ³ã‚°ã—ãªã„ã‚ˆã†ã«ã—ã¦ãã ã•ã„ï¼‰

```bash
# vi config.yaml
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
kubernetesVersion: v1.30.2
controlPlaneEndpoint: "192.168.21.30:8443"
networking:
  podSubnet: "10.20.0.0/16"

# kubeadm init --config ./config.yaml --upload-certs

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of the control-plane node running the following command on each as root:

  kubeadm join vip-address:8443 --token ********************** \
        --discovery-token-ca-cert-hash sha256:********************** \
        --control-plane --certificate-key **********************

Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
"kubeadm init phase upload-certs --upload-certs" to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join vip-address:8443 --token ********************** \
        --discovery-token-ca-cert-hash sha256:**********************
```

å®Ÿè¡Œå¾Œã«è¨˜è¼‰ã®ã‚ã‚‹é€šã‚Šã«ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

```bash
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
export KUBECONFIG=/etc/kubernetes/admin.conf
```

å¯¾è±¡ï¼šã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ³ãƒãƒ¼ãƒ‰

ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ³ã¨ã—ã¦å‚åŠ ã•ã›ã¾ã™ã€‚

```bash
 kubeadm join kube-vip-address:8443 --token ********************** \
       --discovery-token-ca-cert-hash sha256:********************** \
       --control-plane --certificate-key **********************
```

å‚åŠ ã•ã›ãŸå¾Œã«è¨˜è¼‰ã®ã‚ã‚‹é€šã‚Šã«ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

```bash
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

å¯¾è±¡ï¼šãƒ¯ãƒ¼ã‚«ãƒ¼ãƒãƒ¼ãƒ‰

ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒãƒ¼ãƒ‰ã¨ã—ã¦å‚åŠ ã•ã›ã¾ã™ã€‚

```bash
 kubeadm join kube-vip-address:8443 --token ********************** \
       --discovery-token-ca-cert-hash sha256:********************** \
```

# kubernetesã®çŠ¶æ³ç¢ºèª

---

å¯¾è±¡ï¼šã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ³ãƒãƒ¼ãƒ‰ã®ã©ã“ã‹1å°ã§å®Ÿæ–½

ã‚¯ãƒ©ã‚¹ã‚¿ã¸ã®å‚åŠ ã¯å•é¡Œãªãã§ãã¦ãŠã‚Šã¾ã™ãŒã€STATUSæ¬„ãŒNotReadyçŠ¶æ…‹ã¨ãªã£ã¦ã„ã¾ã™ã€‚

ã“ã‚Œã¯ç•°ãªã‚‹ãƒ›ã‚¹ãƒˆä¸Šã§ã®Podé–“é€šä¿¡ã®è¨­å®šï¼ˆCNIãƒ—ãƒ©ã‚°ã‚¤ãƒ³ï¼‰ãŒã§ãã¦ã„ãªã„ãŸã‚ã¨ãªã‚Šã¾ã™ã€‚

```bash
# kubectl get node
NAME       STATUS     ROLES           AGE   VERSION
master01   NotReady      control-plane   21h   v1.30.2
master02   NotReady      control-plane   21h   v1.30.2
master03   NotReady   control-plane   18m   v1.30.2
master04   NotReady      control-plane   21h   v1.30.2
master05   NotReady      control-plane   21h   v1.30.2
worker01   NotReady      <none>          21h   v1.30.2
worker02   NotReady      <none>          21h   v1.30.2
worker03   NotReady      <none>          21h   v1.30.2
```

æ¬¡ã«Podã®çŠ¶æ³ã‚’ç¢ºèªã—ã¾ã™ã€‚

corednsã®STATUSãŒPendingã«ãªã£ã¦ã„ã‚‹ã®ã‚‚ç•°ãªã‚‹ãƒ›ã‚¹ãƒˆä¸Šã§ã®Podé–“é€šä¿¡ã®è¨­å®šãŒã§ãã¦ã„ãªã„ãŸã‚ã¨ãªã‚Šã¾ã™ã€‚

```bash
# kubectl get pod -n kube-system
NAME                               READY   STATUS    RESTARTS         AGE
coredns-7db6d8ff4d-frdkx           0/1     ContainerCreating   0      21h
coredns-7db6d8ff4d-sqzkj           0/1     ContainerCreating   0      21h
etcd-master01                      1/1     Running   1 (3h55m ago)    21h
etcd-master02                      1/1     Running   1 (3h54m ago)    21h
etcd-master03                      1/1     Running   0                20m
etcd-master04                      1/1     Running   1 (3h52m ago)    21h
etcd-master05                      1/1     Running   1 (3h51m ago)    21h
kube-apiserver-master01            1/1     Running   1 (3h55m ago)    21h
kube-apiserver-master02            1/1     Running   1 (3h54m ago)    21h
kube-apiserver-master03            1/1     Running   0                20m
kube-apiserver-master04            1/1     Running   2 (3h51m ago)    21h
kube-apiserver-master05            1/1     Running   2 (3h50m ago)    21h
kube-controller-manager-master01   1/1     Running   11 (3h55m ago)   21h
kube-controller-manager-master02   1/1     Running   11 (3h54m ago)   21h
kube-controller-manager-master03   1/1     Running   0                20m
kube-controller-manager-master04   1/1     Running   9 (3h52m ago)    21h
kube-controller-manager-master05   1/1     Running   6 (3h51m ago)    21h
kube-proxy-5wkr8                   1/1     Running   1 (3h55m ago)    21h
kube-proxy-6kbhw                   1/1     Running   1 (3h52m ago)    21h
kube-proxy-c2lw5                   1/1     Running   1 (3h51m ago)    21h
kube-proxy-hxngr                   1/1     Running   1 (3h54m ago)    21h
kube-proxy-j7mv5                   1/1     Running   1 (3h51m ago)    21h
kube-proxy-n2ktb                   1/1     Running   0                20m
kube-proxy-rgx6p                   1/1     Running   1 (3h51m ago)    21h
kube-proxy-txck6                   1/1     Running   1 (3h51m ago)    21h
kube-scheduler-master01            1/1     Running   12 (3h55m ago)   21h
kube-scheduler-master02            1/1     Running   11 (3h54m ago)   21h
kube-scheduler-master03            1/1     Running   0                20m
kube-scheduler-master04            1/1     Running   10 (3h52m ago)   21h
kube-scheduler-master05            1/1     Running   7 (3h51m ago)    21h

```

# Calicoã®è¨­å®š

---

å¯¾è±¡ï¼šmaster01 

ç•°ãªã‚‹ãƒ›ã‚¹ãƒˆä¸Šã§ã®Podé–“é€šä¿¡ã®è¨­å®šãŒã§ãã¦ã„ãªã„ã®ã§CNIãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®è¨­å®šã‚’ã—ã¾ã™ã€‚

æœ¬æŠ•ç¨¿ã§ã¯Calicoã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ãŒã€ä»–ã«ã‚‚FlannelãŒã‚ã‚Šã¾ã™ã€‚

### Flannelã¨ã¯

ã‚·ãƒ³ãƒ—ãƒ«ãªCNIãƒ—ãƒ©ã‚°ã‚¤ãƒ³

Linuxã‚«ãƒ¼ãƒãƒ«ã®æ©Ÿèƒ½ã‚’åˆ©ç”¨ã—ä»®æƒ³ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç”¨ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«VXLANã‚’åˆ©ç”¨ã—ã¦ã€

ãƒãƒ¼ãƒ‰é–“ã®OverrayNetworkã‚’æ§‹æˆã—ã‚³ãƒ³ãƒ†ãƒŠå‘ã‘ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½œæˆ

ãƒãƒ¼ãƒ‰å†…ã®ã€Œflannel.1ã€ã¨ã„ã†ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ã§ãƒãƒ¼ãƒ‰ã‚’ã¾ãŸãPodé–“é€šä¿¡ã‚’VXLANã«ã‚ˆã£ã¦ã‚«ãƒ—ã‚»ãƒ«ã—ã€

ãƒˆãƒ³ãƒãƒªãƒ³ã‚°ã‚’ã—ã¦ä»–ã®ãƒãƒ¼ãƒ‰ã«å±Šã‘ã¾ã™ã€‚å—ä¿¡ã—ãŸãƒãƒ¼ãƒ‰ãŒã‚«ãƒ—ã‚»ãƒ«åŒ–ã‚’è§£ãã€PodåŒå£«ã®é€šä¿¡ãŒå®Ÿç¾

### Calicoã¨ã¯

ãƒãƒ¼ãƒ‰ã‚’ã¾ãŸãPodé–“é€šä¿¡ã‚’Flannelã®ã‚ˆã†ã«ã‚«ãƒ—ã‚»ãƒ«åŒ–ã™ã‚‹æ–¹æ³•ã¨ã€ã‚«ãƒ—ã‚»ãƒ«åŒ–ã—ãªã„æ–¹æ³•ã®ã©ã¡ã‚‰ã‹ã‚’é¸æŠã™ã‚‹ã“ã¨ãŒå¯èƒ½

Calicoã¯å„ãƒãƒ¼ãƒ‰ã«ã€PodãŒåˆ©ç”¨ã™ã‚‹CIDRã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å‰²ã‚Šå½“ã¦ã‚‹

å„ãƒãƒ¼ãƒ‰å†…ã§èµ·å‹•ã™ã‚‹BIRDãŒã€Pod CIDRã‚’çµŒè·¯æƒ…å ±ã¨ã—ã¦äº¤æ›ã—ã€ãƒãƒ¼ãƒ‰å†…ã®ãƒ«ãƒ¼ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã«åæ˜ 

ãƒãƒ¼ãƒ‰ã¯PodãŒé€ä¿¡ã—ãŸãƒ‘ã‚±ãƒƒãƒˆã‚’ãƒ«ãƒ¼ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã«åŸºã¥ã„ã¦å®›å…ˆPodãŒå­˜åœ¨ã™ã‚‹ãƒãƒ¼ãƒ‰ã«è»¢é€ã—ã€

ãƒ‘ã‚±ãƒƒãƒˆã¯å—ä¿¡å…ˆã®ãƒãƒ¼ãƒ‰å†…ã®ãƒ«ãƒ¼ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å‚ç…§ã—ã¦å®›å…ˆPodã«å±Šã

Calicoã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€ä»¥ä¸‹ï¼‹ã®éƒ¨åˆ†ã«ãªã£ã¦ã„ã‚‹ã¨ã“ã‚ã‚’ä¿®æ­£ã—ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã™ã€‚# 

```bash
# kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/master/manifests/tigera-operator.yaml
# curl -OL https://raw.githubusercontent.com/projectcalico/calico/master/manifests/calico.yaml
# cp -p calico.yaml calico.yaml.org
# vi calico.yaml
4996             - name: CALICO_IPV4POOL_CIDR
4997               value: "10.20.0.0/16"

# kubectl apply -f custom-resources.yaml
```

Calicoã®è¨­å®šãŒå®Œäº†ã™ã‚Œã°Nodeé–“é€šä¿¡ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ãŸã‚Nodeã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒReadyã¨ãªã‚Šã€

corednsã‚‚Runningã«ãªã‚Šã€calicoã‚‚Runningã«ãªã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚

â€»CalicoãŒPodã¨ã—ã¦èµ·å‹•ã™ã‚‹ã«ã¯æ™‚é–“ãŒã‹ã‹ã£ãŸã®ã§æ°—é•·ã«å¾…ã¡ã¾ã—ã‚‡ã†ã€‚

```bash
# kubectl get node
NAME       STATUS   ROLES           AGE   VERSION
master01   Ready    control-plane   21h   v1.30.2
master02   Ready    control-plane   21h   v1.30.2
master03   Ready    control-plane   25m   v1.30.2
master04   Ready    control-plane   21h   v1.30.2
master05   Ready    control-plane   21h   v1.30.2
worker01   Ready    <none>          21h   v1.30.2
worker02   Ready    <none>          21h   v1.30.2
worker03   Ready    <none>          21h   v1.30.2

# kubectl get pods -n calico-system
NAME                                       READY   STATUS    RESTARTS        AGE
calico-kube-controllers-5d8479686c-fzq85   1/1     Running   1 (4h1m ago)    21h
calico-node-2vvlk                          1/1     Running   1 (3h58m ago)   21h
calico-node-bwdx2                          1/1     Running   1 (4h1m ago)    21h
calico-node-j87qz                          1/1     Running   3 (4h1m ago)    21h
calico-node-jtmkt                          1/1     Running   1 (3h57m ago)   21h
calico-node-ljxh2                          1/1     Running   1 (116s ago)    26m
calico-node-r6tqg                          1/1     Running   1 (3h58m ago)   21h
calico-node-rmch5                          1/1     Running   1 (3h58m ago)   21h
calico-node-w74f2                          1/1     Running   1 (3h57m ago)   21h
calico-typha-5856fcf8f5-bh7zj              1/1     Running   1 (3h58m ago)   21h
calico-typha-5856fcf8f5-mflq8              1/1     Running   1 (3h58m ago)   21h
calico-typha-5856fcf8f5-wtpjl              1/1     Running   1 (3h57m ago)   21h
csi-node-driver-46gpp                      2/2     Running   2 (3h58m ago)   21h
csi-node-driver-b6tvl                      2/2     Running   2 (4h1m ago)    21h
csi-node-driver-bwmp2                      2/2     Running   2 (3h58m ago)   21h
csi-node-driver-ch52x                      2/2     Running   0               7m37s
csi-node-driver-hm59p                      2/2     Running   2 (3h57m ago)   21h
csi-node-driver-kxr6l                      2/2     Running   2 (4h1m ago)    21h
csi-node-driver-wjcdx                      2/2     Running   2 (3h58m ago)   21h
csi-node-driver-zm8wh                      2/2     Running   2 (3h57m ago)   21h
```

# MetalLBã®è¨­å®š

---

MetalLBã¨ã¯kubernetesã§ã‚µãƒ¼ãƒ“ã‚¹ã‚’å¤–éƒ¨å…¬é–‹ã™ã‚‹éš›ã«ã¯type: LoadBlancerã‚’åˆ©ç”¨ã—ã¾ã™ãŒã€ã‚ªãƒ³ãƒ—ãƒ¬ãƒŸã‚¹ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚

ãã‚Œã‚’è§£æ±ºã™ã‚‹ã®ãŒMetalLBã¨ãªã‚Šã€æ©Ÿèƒ½ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã“ã¨ã§ã‚ªãƒ³ãƒ—ãƒ¬ãƒŸã‚¹ç’°å¢ƒã§ã‚‚åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

MetalLBã‚’å‹•ã‹ã™ã¨speakerã¨controllerã®PodãŒå‹•ä½œã—ã¾ã™ã€‚

## controllerã¨ã¯

Deploymetnã«ã‚ˆã£ã¦ç®¡ç†ã•ã‚Œã‚‹Podã¨ãªã‚Šã€MetalLBã§åˆ©ç”¨ã™ã‚‹IPã‚¢ãƒ‰ãƒ¬ã‚¹ã®ç®¡ç†ã‚’æ‹…ã„ã¾ã™ã€‚

## speakerã¨ã¯

Nodeã§1å°ãšã¤å‹•ä½œã™ã‚‹Podã«ãªã‚Šã€ARPï¼ˆL2ï¼‰ / NDPï¼ˆipv6 L2ï¼‰ / BGPï¼ˆL3ï¼‰ã‚’ä½¿ã£ã¦ã‚µãƒ¼ãƒ“ã‚¹ã®é€šä¿¡åˆ°é”ã‚’æ‹…ä¿ã—ã¾ã™ã€‚

MetalLBã«ã¯L2ãƒ¢ãƒ¼ãƒ‰ã¨BGPãƒ¢ãƒ¼ãƒ‰ã®2ã¤ã‚ã‚Šã¾ã™ã€‚

ä»Šå›ã¯L2ãƒ¢ãƒ¼ãƒ‰ã‚’åˆ©ç”¨ã™ã‚‹ã®ã§ã€L2ãƒ¢ãƒ¼ãƒ‰ã®è§£èª¬ã‚’æŒŸã¿ãŸã„ã¨æ€ã„ã¾ã™ã€‚

L2ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã§ã‚µãƒ¼ãƒ“ã‚¹ã‚’å…¬é–‹ã™ã‚‹å ´åˆã€å„ãƒãƒ¼ãƒ‰ã§ã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã™ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ãŒã€

ip aã‚³ãƒãƒ³ãƒ‰ãªã©å®Ÿè¡Œã—ã¦ã‚‚å®Ÿéš›ã«NICã«ã¯ç´ã¥ã‹ãšã€æ‰•ã„å‡ºã•ã‚ŒãŸIPã«å¯¾ã™ã‚‹é€šä¿¡ã¯1å°ã®ãƒãƒ¼ãƒ‰ã«é›†ç´„ã•ã‚Œã€

kube-proxyã«ã‚ˆã£ã¦è¨­å®šã•ã‚ŒãŸiptablesãƒ«ãƒ¼ãƒ«ã«å¾“ã„ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’Podã«åˆ†æ•£ã—ã¾ã™ã€‚

ãªã®ã§L2ãƒ¢ãƒ¼ãƒ‰ã§ã¯IPã‚’æŒã¤ãƒãƒ¼ãƒ‰ãŒãƒ€ã‚¦ãƒ³ã™ã‚‹ã¨åˆ¥ã®ãƒãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ã‚ã‚‹ãŸã‚LBã¨ã„ã†ã‚ˆã‚Šã¯FailOverã™ã‚‹å†—é•·åŒ–æ©Ÿèƒ½ãŒæ­£ã—ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚

IPã‚’æŒã¤ãƒãƒ¼ãƒ‰ã®ç®¡ç†ã«ã¤ã„ã¦ã¯speakerã‹ã‚‰ãƒªãƒ¼ãƒ€ãŒ1å°æ‰•ã„å‡ºã•ã‚Œã¾ã™ã€‚

ãªãŠL2ãƒ¢ãƒ¼ãƒ‰ã§ã¯ã€ŒFailOverã™ã‚‹å†—é•·åŒ–æ©Ÿèƒ½ãŒæ­£ã—ã„ã‹ã‚‚ã€ã¨ãŠä¼ãˆã—ã¾ã—ãŸãŒã€

kubernetesè‡ªä½“ãŒNodeDownã‚’æ¤œçŸ¥ã™ã‚‹ãŸã‚ã€node-monitor-grace-periodã§è¨­å®šã—ãŸæ™‚é–“+Podã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¯5åˆ†ã‹ã‹ã‚‹ãŸã‚ã€

åˆ‡ã‚Šæ›¿ã‚ã‚Šã«ã¯5åˆ†ä»¥ä¸Šã‹ã‹ã‚‹ã®ã§æ³¨æ„ãŒå¿…è¦ã§ã™ã€‚

å‚è€ƒURLï¼š[https://kubernetes.io/ja/docs/concepts/architecture/nodes/#condition](https://kubernetes.io/ja/docs/concepts/architecture/nodes/#condition)

<aside>
ğŸ’¡

Ready conditionãŒ`pod-eviction-timeout`([kube-controller-manager](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/)ã«æ¸¡ã•ã‚ŒãŸå¼•æ•°)ã«è¨­å®šã•ã‚ŒãŸæ™‚é–“ã‚’è¶…ãˆã¦ã‚‚`Unknown`ã‚„`False`ã®ã¾ã¾ã«ãªã£ã¦ã„ã‚‹å ´åˆã€è©²å½“ãƒãƒ¼ãƒ‰ä¸Šã«ã‚ã‚‹Podã¯ãƒãƒ¼ãƒ‰ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã«ã‚ˆã£ã¦å‰Šé™¤ãŒã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã•ã‚Œã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®é€€å½¹ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®æ™‚é–“ã¯**5åˆ†**ã§ã™ã€‚ãƒãƒ¼ãƒ‰ãŒåˆ°é”ä¸èƒ½ãªã„ãã¤ã‹ã®å ´åˆã«ãŠã„ã¦ã¯ã€APIã‚µãƒ¼ãƒãƒ¼ãŒè©²å½“ãƒãƒ¼ãƒ‰ã®kubeletã¨ç–é€šã§ããªã„çŠ¶æ…‹ã«ãªã£ã¦ã„ã¾ã™ã€‚ãã®å ´åˆã€APIã‚µãƒ¼ãƒãƒ¼ãŒkubeletã¨å†ã³é€šä¿¡ã‚’ç¢ºç«‹ã™ã‚‹ã¾ã§ã®é–“ã€Podã®å‰Šé™¤ã‚’è¡Œã†ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚å‰Šé™¤ãŒã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã•ã‚Œã‚‹ã¾ã§ã®é–“ã€å‰Šé™¤å¯¾è±¡ã®Podã¯åˆ‡ã‚Šé›¢ã•ã‚ŒãŸãƒãƒ¼ãƒ‰ã®ä¸Šã§ç¨¼åƒã‚’ç¶šã‘ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚

</aside>

ã¾ãŸã‚‚ã†ä¸€ã¤ã®æ³¨æ„ã¨ã—ã¦ã¯ãƒªãƒ¼ãƒ€ãƒ¼ã¨ã—ã¦é¸å‡ºã•ã‚ŒãŸãƒãƒ¼ãƒ‰ã«ã¦é›†ç´„ã•ã‚Œã‚‹ã®ã§ã€

NICã®å¸¯åŸŸä¸Šé™ãŒé€šä¿¡ã®é™ç•Œï¼ˆè‡ªå®…ã§å‹•ã‹ã™ã«ã¯ã‚ˆã£ã½ã©ã®ã“ã¨ãŒãªã„é™ã‚Šå¤§ä¸ˆå¤«ã ã¨æ€ã„ã¾ã™ãŒï¼‰ã¨ãªã‚Šã¾ã™ã€‚

ãƒ‡ãƒ—ãƒ­ã‚¤ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å®Ÿæ–½ã—ã¾ã™ã€‚

```bash
# curl -O https://raw.githubusercontent.com/metallb/metallb/v0.13.10/config/manifests/metallb-native.yaml
# kubectl apply -f metallb-native.yaml
# kubectl get all -n metallb-system
NAME                              READY   STATUS    RESTARTS      AGE
pod/controller-595f88d88f-jncfq   1/1     Running   1 (12s ago)   63s
pod/speaker-4r7jb                 1/1     Running   0             63s
pod/speaker-chj5z                 1/1     Running   0             63s
pod/speaker-clszj                 1/1     Running   0             63s
pod/speaker-cnwgh                 1/1     Running   0             63s
pod/speaker-gxvft                 1/1     Running   0             63s
pod/speaker-hct2b                 1/1     Running   0             63s
pod/speaker-jqsfl                 1/1     Running   0             63s
pod/speaker-mtkxr                 1/1     Running   0             63s

NAME                      TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
service/webhook-service   ClusterIP   10.101.93.11   <none>        443/TCP   63s

NAME                     DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
daemonset.apps/speaker   8         8         8       8            8           kubernetes.io/os=linux   63s

NAME                         READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/controller   1/1     1            1           63s

NAME                                    DESIRED   CURRENT   READY   AGE
replicaset.apps/controller-595f88d88f   1         1         1       63s
```

Helmã‚’ä½¿ã†å ´åˆã«ã¯ä»¥ä¸‹

```bash
# curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
# chmod 700 get_helm.sh
# ./get_helm.sh

# kubectl create namespace metallb
# helm repo add metallb https://metallb.github.io/metallb
# helm install metallb metallb/metallb --namespace metallb
```

MetalLBãŒè‡ªå‹•çš„ã«LBã‚’æ‰•ã„å‡ºã—ã¦ã‚‚ã‚‰ã†ãŸã‚ã«ãƒ¬ãƒ³ã‚¸ã‚’è¨­å®šã—ã¾ã™ã€‚

```bash
# cat <<EOF > metallb-config.yaml 
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: default
  namespace: metallb-system
spec:
  addresses:
  - IPã‚¢ãƒ‰ãƒ¬ã‚¹ç¯„å›²é–‹å§‹-IPã‚¢ãƒ‰ãƒ¬ã‚¹ç¯„å›²çµ‚äº†
  autoAssign: true
---
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: default
  namespace: metallb-system
spec:
  ipAddressPools:
  - default
EOF

# kubectl apply -f metallb-config.yaml 
# kubectl get configmap -n metallb-system
NAME               DATA   AGE
kube-root-ca.crt   1      3h3m
```

# CSIã®è¨­å®š

---

CSIã¨ã¯Container Storage Interfaceã¨ã„ã„ã€ã‚³ãƒ³ãƒ†ãƒŠã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‘ã‘ã«ä½œã‚‰ã‚ŒãŸã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ã™ã€‚

æœ¬æ©Ÿèƒ½ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§Podå†…ã§å‹•ã„ã¦ã„ã‚‹ã‚³ãƒ³ãƒ†ãƒŠãŒè¤‡æ•°åŒã˜Volumeã‚’è¦‹ã«ã„ãã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã‚Šã€

PVCã‚„PVã®ã‚µã‚¤ã‚ºã‚’æ‹¡å¼µã§ããŸã‚Šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

ã“ã‚Œã‚’å®Ÿç¾ã™ã‚‹å‰ã«ã¯è‡ªå®…ã§NFSã‚µãƒ¼ãƒã‚’ä½¿ã£ã¦nfs-subdir-external-provisionerã‚’åˆ©ç”¨ã—ã¦ã„ã¾ã—ãŸãŒã€

PVCã‚„PVã®ã‚µã‚¤ã‚ºã‚’æ‹¡å¼µãŒã§ããªã„ãŸã‚æ­¯ãŒã‚†ã„æ€ã„ã‚’ã—ã¦ãã¾ã—ãŸãŒæˆ‘ãŒå®¶ã«Synologyã®NASãŒæ¥ãŸã®ã§ã€

ã‚ˆã†ã‚„ãCSIã‚’ä½¿ã†ã“ã¨ãŒã§ãã¾ã™ğŸ‘

Synolodyã®NASã§ã‚ã‚‹CSI Driverã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã®æ‰‹é †ã¯ä»¥ä¸‹ã§ã™ã€‚

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯Githubã«ä¹—ã£ã¦ã„ã‚‹ã®ã§å‚è€ƒã«ã—ã¦ã¿ã¦ãã ã•ã„ã€‚

[https://github.com/SynologyOpenSource/synology-csi](https://github.com/SynologyOpenSource/synology-csi)

```bash
Workerãƒãƒ¼ãƒ‰ã«ä»¥ä¸‹ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ã‹ã‚‰å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
# apt install -y open-iscsi

Synology CSI Install
# git clone https://github.com/SynologyOpenSource/synology-csi.git
# cd synology-csi
# cp config/client-info-template.yml config/client-info.yml
# cat config/client-info.yml
---
clients:
  - host: NASã®IPã‚¢ãƒ‰ãƒ¬ã‚¹
    port: 5000
    https: false
    username: ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå 
    password: ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰

# cat deploy/kubernetes/v1.20/storage-class.yml 
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: synology-iscsi-storage
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
provisioner: csi.san.synology.com
# if all params are empty, synology CSI will choose an available location to create volume
parameters:
  dsm: 'IPã‚¢ãƒ‰ãƒ¬ã‚¹'
  location: '/volumeã®ãƒ‘ã‚¹'
  fsType: 'ext4'
reclaimPolicy: Delete 
allowVolumeExpansion: true

# ./scripts/deploy.sh install --all
â†’k8sã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒv1.28ã‹ã‚‰versionç¢ºèªæ–¹æ³•ãŒå¤‰ã‚ã£ã¦ã„ã‚‹ã®ã§ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä¸­èº«ã‚’å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚
 ver=$(kubectl version | grep Server | awk '{print $3}')
```

ã“ã‚Œã§åŸºæœ¬çš„ãªæ©Ÿèƒ½ã‚’kubernetesä¸Šã«è¼‰ã›ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã®ã§ã€

ã“ã®å…ˆã¯ç§è‡ªèº«ãŒã©ã‚Œã ã‘kubernetesã‚’ä½¿ã„ã“ãªã›ã‚‹ã‹â‰ï¸

ã«ãªã‚‹ã®ã§ãƒªã‚½ãƒ¼ã‚¹è³¼å…¥å°ã®ã‚³ã‚¹ãƒˆå›åãŒã§ãã‚‹ãã‚‰ã„å‹‰å¼·ã«åŠ±ã¿ãŸã„ã¨æ€ã„ã¾ã™ã€‚